{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "l8N81jp-0-me"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the charity_data.csv\n",
        "url = \"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\"\n",
        "application_df = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "mKSv8Dw61aPa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing"
      ],
      "metadata": {
        "id": "Mj6lmBCF1n2B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Drop non-beneficial columns\n",
        "application_df = application_df.drop(['EIN', 'NAME'], axis=1)\n",
        "\n",
        "#Process categorical columns\n",
        "application_df = pd.get_dummies(application_df, drop_first=True)"
      ],
      "metadata": {
        "id": "gjZIcV631wtW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Split data into features and target\n",
        "X = application_df.drop(['IS_SUCCESSFUL'], axis=1)\n",
        "y = application_df['IS_SUCCESSFUL']\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "PPNaGJ5t2NeF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Design and Optimization Attempts"
      ],
      "metadata": {
        "id": "P4rC3Qw92hci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Attempt 1: Base Model with Additional Epochs\n",
        "\n",
        "# Define the base model\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# Input layer and first hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=80, input_dim=len(X_train_scaled[0]), activation=\"relu\"))\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=30, activation=\"relu\"))\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Compile the model\n",
        "nn.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model\n",
        "history = nn.fit(X_train_scaled, y_train, epochs=50, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0AwHMDV2mfe",
        "outputId": "df3efb43-e030-40b6-f8c4-423ba2bf0f6e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6802 - loss: 0.6190 - val_accuracy: 0.7380 - val_loss: 0.5565\n",
            "Epoch 2/50\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7235 - loss: 0.5582 - val_accuracy: 0.7378 - val_loss: 0.5557\n",
            "Epoch 3/50\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7288 - loss: 0.5556 - val_accuracy: 0.7358 - val_loss: 0.5533\n",
            "Epoch 4/50\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7265 - loss: 0.5543 - val_accuracy: 0.7376 - val_loss: 0.5491\n",
            "Epoch 5/50\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7397 - loss: 0.5412 - val_accuracy: 0.7387 - val_loss: 0.5486\n",
            "Epoch 6/50\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7285 - loss: 0.5467 - val_accuracy: 0.7387 - val_loss: 0.5503\n",
            "Epoch 7/50\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7325 - loss: 0.5436 - val_accuracy: 0.7418 - val_loss: 0.5482\n",
            "Epoch 8/50\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7262 - loss: 0.5516 - val_accuracy: 0.7396 - val_loss: 0.5452\n",
            "Epoch 9/50\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7376 - loss: 0.5379 - val_accuracy: 0.7389 - val_loss: 0.5497\n",
            "Epoch 10/50\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7284 - loss: 0.5446 - val_accuracy: 0.7411 - val_loss: 0.5452\n",
            "Epoch 11/50\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7357 - loss: 0.5417 - val_accuracy: 0.7332 - val_loss: 0.5485\n",
            "Epoch 12/50\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7330 - loss: 0.5401 - val_accuracy: 0.7418 - val_loss: 0.5458\n",
            "Epoch 13/50\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7352 - loss: 0.5413 - val_accuracy: 0.7422 - val_loss: 0.5481\n",
            "Epoch 14/50\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7354 - loss: 0.5430 - val_accuracy: 0.7402 - val_loss: 0.5467\n",
            "Epoch 15/50\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7348 - loss: 0.5409 - val_accuracy: 0.7422 - val_loss: 0.5492\n",
            "Epoch 16/50\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7361 - loss: 0.5408 - val_accuracy: 0.7429 - val_loss: 0.5475\n",
            "Epoch 17/50\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7354 - loss: 0.5393 - val_accuracy: 0.7402 - val_loss: 0.5480\n",
            "Epoch 18/50\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7370 - loss: 0.5394 - val_accuracy: 0.7423 - val_loss: 0.5450\n",
            "Epoch 19/50\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7301 - loss: 0.5410 - val_accuracy: 0.7420 - val_loss: 0.5497\n",
            "Epoch 20/50\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7402 - loss: 0.5356 - val_accuracy: 0.7409 - val_loss: 0.5497\n",
            "Epoch 21/50\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7368 - loss: 0.5375 - val_accuracy: 0.7423 - val_loss: 0.5436\n",
            "Epoch 22/50\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7369 - loss: 0.5358 - val_accuracy: 0.7429 - val_loss: 0.5467\n",
            "Epoch 23/50\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7393 - loss: 0.5374 - val_accuracy: 0.7402 - val_loss: 0.5503\n",
            "Epoch 24/50\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7346 - loss: 0.5410 - val_accuracy: 0.7413 - val_loss: 0.5469\n",
            "Epoch 25/50\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7368 - loss: 0.5378 - val_accuracy: 0.7402 - val_loss: 0.5488\n",
            "Epoch 26/50\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7337 - loss: 0.5431 - val_accuracy: 0.7413 - val_loss: 0.5478\n",
            "Epoch 27/50\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7335 - loss: 0.5387 - val_accuracy: 0.7389 - val_loss: 0.5466\n",
            "Epoch 28/50\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7369 - loss: 0.5376 - val_accuracy: 0.7409 - val_loss: 0.5494\n",
            "Epoch 29/50\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7335 - loss: 0.5376 - val_accuracy: 0.7394 - val_loss: 0.5495\n",
            "Epoch 30/50\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7367 - loss: 0.5332 - val_accuracy: 0.7425 - val_loss: 0.5484\n",
            "Epoch 31/50\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7366 - loss: 0.5390 - val_accuracy: 0.7418 - val_loss: 0.5444\n",
            "Epoch 32/50\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7351 - loss: 0.5358 - val_accuracy: 0.7391 - val_loss: 0.5500\n",
            "Epoch 33/50\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7364 - loss: 0.5333 - val_accuracy: 0.7403 - val_loss: 0.5475\n",
            "Epoch 34/50\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7364 - loss: 0.5357 - val_accuracy: 0.7409 - val_loss: 0.5502\n",
            "Epoch 35/50\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7379 - loss: 0.5335 - val_accuracy: 0.7413 - val_loss: 0.5497\n",
            "Epoch 36/50\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7477 - loss: 0.5300 - val_accuracy: 0.7414 - val_loss: 0.5468\n",
            "Epoch 37/50\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7384 - loss: 0.5325 - val_accuracy: 0.7409 - val_loss: 0.5512\n",
            "Epoch 38/50\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7343 - loss: 0.5395 - val_accuracy: 0.7407 - val_loss: 0.5517\n",
            "Epoch 39/50\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7374 - loss: 0.5363 - val_accuracy: 0.7422 - val_loss: 0.5522\n",
            "Epoch 40/50\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7382 - loss: 0.5361 - val_accuracy: 0.7394 - val_loss: 0.5530\n",
            "Epoch 41/50\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7419 - loss: 0.5314 - val_accuracy: 0.7414 - val_loss: 0.5491\n",
            "Epoch 42/50\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7359 - loss: 0.5385 - val_accuracy: 0.7413 - val_loss: 0.5542\n",
            "Epoch 43/50\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7353 - loss: 0.5348 - val_accuracy: 0.7403 - val_loss: 0.5500\n",
            "Epoch 44/50\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7413 - loss: 0.5321 - val_accuracy: 0.7418 - val_loss: 0.5498\n",
            "Epoch 45/50\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7336 - loss: 0.5376 - val_accuracy: 0.7433 - val_loss: 0.5481\n",
            "Epoch 46/50\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7395 - loss: 0.5343 - val_accuracy: 0.7414 - val_loss: 0.5504\n",
            "Epoch 47/50\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7399 - loss: 0.5325 - val_accuracy: 0.7413 - val_loss: 0.5530\n",
            "Epoch 48/50\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7383 - loss: 0.5322 - val_accuracy: 0.7414 - val_loss: 0.5495\n",
            "Epoch 49/50\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7383 - loss: 0.5312 - val_accuracy: 0.7438 - val_loss: 0.5472\n",
            "Epoch 50/50\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7424 - loss: 0.5302 - val_accuracy: 0.7418 - val_loss: 0.5498\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Attempt 2: Adding More Neurons and Layers\n",
        "\n",
        "# Define a deeper model\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# Input layer and additional hidden layers\n",
        "nn.add(tf.keras.layers.Dense(units=100, input_dim=len(X_train_scaled[0]), activation=\"relu\"))\n",
        "nn.add(tf.keras.layers.Dense(units=50, activation=\"relu\"))\n",
        "nn.add(tf.keras.layers.Dense(units=30, activation=\"relu\"))\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Compile and train\n",
        "nn.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "history = nn.fit(X_train_scaled, y_train, epochs=100, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HN7xCvIt3XSD",
        "outputId": "19f60220-67ae-41f0-e1cf-0d8def4528bd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6987 - loss: 0.5999 - val_accuracy: 0.7383 - val_loss: 0.5658\n",
            "Epoch 2/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7261 - loss: 0.5536 - val_accuracy: 0.7413 - val_loss: 0.5499\n",
            "Epoch 3/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7317 - loss: 0.5489 - val_accuracy: 0.7392 - val_loss: 0.5476\n",
            "Epoch 4/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7291 - loss: 0.5497 - val_accuracy: 0.7356 - val_loss: 0.5498\n",
            "Epoch 5/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7302 - loss: 0.5447 - val_accuracy: 0.7349 - val_loss: 0.5512\n",
            "Epoch 6/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7332 - loss: 0.5463 - val_accuracy: 0.7391 - val_loss: 0.5524\n",
            "Epoch 7/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7382 - loss: 0.5428 - val_accuracy: 0.7374 - val_loss: 0.5507\n",
            "Epoch 8/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7283 - loss: 0.5466 - val_accuracy: 0.7411 - val_loss: 0.5502\n",
            "Epoch 9/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7271 - loss: 0.5482 - val_accuracy: 0.7425 - val_loss: 0.5456\n",
            "Epoch 10/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7306 - loss: 0.5457 - val_accuracy: 0.7413 - val_loss: 0.5461\n",
            "Epoch 11/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7333 - loss: 0.5395 - val_accuracy: 0.7427 - val_loss: 0.5492\n",
            "Epoch 12/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7370 - loss: 0.5387 - val_accuracy: 0.7433 - val_loss: 0.5453\n",
            "Epoch 13/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7370 - loss: 0.5429 - val_accuracy: 0.7343 - val_loss: 0.5512\n",
            "Epoch 14/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7341 - loss: 0.5396 - val_accuracy: 0.7423 - val_loss: 0.5518\n",
            "Epoch 15/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7332 - loss: 0.5399 - val_accuracy: 0.7418 - val_loss: 0.5466\n",
            "Epoch 16/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7359 - loss: 0.5377 - val_accuracy: 0.7414 - val_loss: 0.5463\n",
            "Epoch 17/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7298 - loss: 0.5437 - val_accuracy: 0.7427 - val_loss: 0.5482\n",
            "Epoch 18/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7389 - loss: 0.5372 - val_accuracy: 0.7429 - val_loss: 0.5514\n",
            "Epoch 19/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7375 - loss: 0.5382 - val_accuracy: 0.7422 - val_loss: 0.5537\n",
            "Epoch 20/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7355 - loss: 0.5381 - val_accuracy: 0.7416 - val_loss: 0.5507\n",
            "Epoch 21/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7379 - loss: 0.5363 - val_accuracy: 0.7423 - val_loss: 0.5486\n",
            "Epoch 22/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7319 - loss: 0.5396 - val_accuracy: 0.7385 - val_loss: 0.5551\n",
            "Epoch 23/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7347 - loss: 0.5425 - val_accuracy: 0.7422 - val_loss: 0.5548\n",
            "Epoch 24/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7375 - loss: 0.5342 - val_accuracy: 0.7409 - val_loss: 0.5501\n",
            "Epoch 25/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7333 - loss: 0.5448 - val_accuracy: 0.7420 - val_loss: 0.5475\n",
            "Epoch 26/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7392 - loss: 0.5350 - val_accuracy: 0.7431 - val_loss: 0.5494\n",
            "Epoch 27/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7401 - loss: 0.5354 - val_accuracy: 0.7423 - val_loss: 0.5474\n",
            "Epoch 28/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7343 - loss: 0.5386 - val_accuracy: 0.7416 - val_loss: 0.5520\n",
            "Epoch 29/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7333 - loss: 0.5405 - val_accuracy: 0.7407 - val_loss: 0.5502\n",
            "Epoch 30/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7366 - loss: 0.5356 - val_accuracy: 0.7413 - val_loss: 0.5517\n",
            "Epoch 31/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7385 - loss: 0.5375 - val_accuracy: 0.7418 - val_loss: 0.5517\n",
            "Epoch 32/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7385 - loss: 0.5330 - val_accuracy: 0.7422 - val_loss: 0.5489\n",
            "Epoch 33/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7419 - loss: 0.5332 - val_accuracy: 0.7418 - val_loss: 0.5529\n",
            "Epoch 34/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7418 - loss: 0.5276 - val_accuracy: 0.7418 - val_loss: 0.5545\n",
            "Epoch 35/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7367 - loss: 0.5326 - val_accuracy: 0.7416 - val_loss: 0.5529\n",
            "Epoch 36/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7332 - loss: 0.5386 - val_accuracy: 0.7409 - val_loss: 0.5503\n",
            "Epoch 37/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7361 - loss: 0.5381 - val_accuracy: 0.7413 - val_loss: 0.5514\n",
            "Epoch 38/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7400 - loss: 0.5304 - val_accuracy: 0.7411 - val_loss: 0.5521\n",
            "Epoch 39/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7419 - loss: 0.5342 - val_accuracy: 0.7427 - val_loss: 0.5514\n",
            "Epoch 40/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7414 - loss: 0.5299 - val_accuracy: 0.7414 - val_loss: 0.5493\n",
            "Epoch 41/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7385 - loss: 0.5324 - val_accuracy: 0.7416 - val_loss: 0.5515\n",
            "Epoch 42/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7349 - loss: 0.5356 - val_accuracy: 0.7414 - val_loss: 0.5507\n",
            "Epoch 43/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7381 - loss: 0.5316 - val_accuracy: 0.7425 - val_loss: 0.5474\n",
            "Epoch 44/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7442 - loss: 0.5269 - val_accuracy: 0.7433 - val_loss: 0.5488\n",
            "Epoch 45/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7416 - loss: 0.5297 - val_accuracy: 0.7416 - val_loss: 0.5482\n",
            "Epoch 46/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7382 - loss: 0.5343 - val_accuracy: 0.7425 - val_loss: 0.5558\n",
            "Epoch 47/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7340 - loss: 0.5367 - val_accuracy: 0.7418 - val_loss: 0.5520\n",
            "Epoch 48/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7430 - loss: 0.5280 - val_accuracy: 0.7420 - val_loss: 0.5545\n",
            "Epoch 49/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7393 - loss: 0.5326 - val_accuracy: 0.7422 - val_loss: 0.5525\n",
            "Epoch 50/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7427 - loss: 0.5256 - val_accuracy: 0.7416 - val_loss: 0.5541\n",
            "Epoch 51/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7482 - loss: 0.5266 - val_accuracy: 0.7431 - val_loss: 0.5542\n",
            "Epoch 52/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7382 - loss: 0.5301 - val_accuracy: 0.7423 - val_loss: 0.5507\n",
            "Epoch 53/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7426 - loss: 0.5314 - val_accuracy: 0.7427 - val_loss: 0.5532\n",
            "Epoch 54/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7413 - loss: 0.5304 - val_accuracy: 0.7416 - val_loss: 0.5532\n",
            "Epoch 55/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7403 - loss: 0.5346 - val_accuracy: 0.7425 - val_loss: 0.5554\n",
            "Epoch 56/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7422 - loss: 0.5281 - val_accuracy: 0.7422 - val_loss: 0.5548\n",
            "Epoch 57/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7410 - loss: 0.5278 - val_accuracy: 0.7423 - val_loss: 0.5536\n",
            "Epoch 58/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7380 - loss: 0.5347 - val_accuracy: 0.7413 - val_loss: 0.5591\n",
            "Epoch 59/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7368 - loss: 0.5315 - val_accuracy: 0.7429 - val_loss: 0.5595\n",
            "Epoch 60/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7449 - loss: 0.5254 - val_accuracy: 0.7425 - val_loss: 0.5570\n",
            "Epoch 61/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7386 - loss: 0.5312 - val_accuracy: 0.7423 - val_loss: 0.5611\n",
            "Epoch 62/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7398 - loss: 0.5293 - val_accuracy: 0.7402 - val_loss: 0.5618\n",
            "Epoch 63/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7379 - loss: 0.5313 - val_accuracy: 0.7405 - val_loss: 0.5572\n",
            "Epoch 64/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7408 - loss: 0.5314 - val_accuracy: 0.7403 - val_loss: 0.5636\n",
            "Epoch 65/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7382 - loss: 0.5322 - val_accuracy: 0.7416 - val_loss: 0.5627\n",
            "Epoch 66/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7395 - loss: 0.5288 - val_accuracy: 0.7411 - val_loss: 0.5579\n",
            "Epoch 67/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7405 - loss: 0.5299 - val_accuracy: 0.7409 - val_loss: 0.5701\n",
            "Epoch 68/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7399 - loss: 0.5330 - val_accuracy: 0.7407 - val_loss: 0.5749\n",
            "Epoch 69/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7442 - loss: 0.5241 - val_accuracy: 0.7402 - val_loss: 0.5645\n",
            "Epoch 70/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7406 - loss: 0.5310 - val_accuracy: 0.7403 - val_loss: 0.5759\n",
            "Epoch 71/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7368 - loss: 0.5348 - val_accuracy: 0.7400 - val_loss: 0.5703\n",
            "Epoch 72/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7461 - loss: 0.5250 - val_accuracy: 0.7402 - val_loss: 0.5673\n",
            "Epoch 73/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7381 - loss: 0.5309 - val_accuracy: 0.7402 - val_loss: 0.5692\n",
            "Epoch 74/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7437 - loss: 0.5268 - val_accuracy: 0.7409 - val_loss: 0.5700\n",
            "Epoch 75/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7426 - loss: 0.5268 - val_accuracy: 0.7398 - val_loss: 0.5688\n",
            "Epoch 76/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7384 - loss: 0.5300 - val_accuracy: 0.7416 - val_loss: 0.5636\n",
            "Epoch 77/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7437 - loss: 0.5272 - val_accuracy: 0.7409 - val_loss: 0.5720\n",
            "Epoch 78/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7396 - loss: 0.5277 - val_accuracy: 0.7403 - val_loss: 0.5712\n",
            "Epoch 79/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7403 - loss: 0.5297 - val_accuracy: 0.7411 - val_loss: 0.5689\n",
            "Epoch 80/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7493 - loss: 0.5199 - val_accuracy: 0.7405 - val_loss: 0.5758\n",
            "Epoch 81/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7371 - loss: 0.5289 - val_accuracy: 0.7407 - val_loss: 0.5704\n",
            "Epoch 82/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7435 - loss: 0.5286 - val_accuracy: 0.7409 - val_loss: 0.5714\n",
            "Epoch 83/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7430 - loss: 0.5268 - val_accuracy: 0.7403 - val_loss: 0.5695\n",
            "Epoch 84/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7426 - loss: 0.5281 - val_accuracy: 0.7402 - val_loss: 0.5703\n",
            "Epoch 85/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7411 - loss: 0.5299 - val_accuracy: 0.7420 - val_loss: 0.5692\n",
            "Epoch 86/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7403 - loss: 0.5281 - val_accuracy: 0.7407 - val_loss: 0.5655\n",
            "Epoch 87/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7424 - loss: 0.5278 - val_accuracy: 0.7402 - val_loss: 0.5694\n",
            "Epoch 88/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7433 - loss: 0.5250 - val_accuracy: 0.7411 - val_loss: 0.5766\n",
            "Epoch 89/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7425 - loss: 0.5262 - val_accuracy: 0.7391 - val_loss: 0.5825\n",
            "Epoch 90/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7432 - loss: 0.5245 - val_accuracy: 0.7411 - val_loss: 0.5665\n",
            "Epoch 91/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7422 - loss: 0.5284 - val_accuracy: 0.7423 - val_loss: 0.5723\n",
            "Epoch 92/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7440 - loss: 0.5244 - val_accuracy: 0.7413 - val_loss: 0.5854\n",
            "Epoch 93/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7370 - loss: 0.5312 - val_accuracy: 0.7414 - val_loss: 0.5716\n",
            "Epoch 94/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7438 - loss: 0.5236 - val_accuracy: 0.7414 - val_loss: 0.5728\n",
            "Epoch 95/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7445 - loss: 0.5234 - val_accuracy: 0.7414 - val_loss: 0.5763\n",
            "Epoch 96/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7407 - loss: 0.5259 - val_accuracy: 0.7416 - val_loss: 0.5741\n",
            "Epoch 97/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7396 - loss: 0.5270 - val_accuracy: 0.7420 - val_loss: 0.5750\n",
            "Epoch 98/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7481 - loss: 0.5195 - val_accuracy: 0.7427 - val_loss: 0.5787\n",
            "Epoch 99/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7456 - loss: 0.5265 - val_accuracy: 0.7423 - val_loss: 0.5747\n",
            "Epoch 100/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7443 - loss: 0.5244 - val_accuracy: 0.7398 - val_loss: 0.5732\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Attempt 3: Experimenting with Activation Functions\n",
        "\n",
        "# Define a model with varied activation functions\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# Input and hidden layers\n",
        "nn.add(tf.keras.layers.Dense(units=120, input_dim=len(X_train_scaled[0]), activation=\"tanh\"))\n",
        "nn.add(tf.keras.layers.Dense(units=60, activation=\"relu\"))\n",
        "nn.add(tf.keras.layers.Dense(units=30, activation=\"tanh\"))\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Compile and train\n",
        "nn.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "history = nn.fit(X_train_scaled, y_train, epochs=150, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvRVBKER4g77",
        "outputId": "5a05a131-8cb2-4006-993b-71f44967fab0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6988 - loss: 0.5887 - val_accuracy: 0.7387 - val_loss: 0.5446\n",
            "Epoch 2/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7286 - loss: 0.5518 - val_accuracy: 0.7371 - val_loss: 0.5479\n",
            "Epoch 3/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7267 - loss: 0.5517 - val_accuracy: 0.7405 - val_loss: 0.5471\n",
            "Epoch 4/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7265 - loss: 0.5499 - val_accuracy: 0.7398 - val_loss: 0.5417\n",
            "Epoch 5/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7327 - loss: 0.5452 - val_accuracy: 0.7376 - val_loss: 0.5446\n",
            "Epoch 6/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7251 - loss: 0.5538 - val_accuracy: 0.7369 - val_loss: 0.5484\n",
            "Epoch 7/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7287 - loss: 0.5436 - val_accuracy: 0.7400 - val_loss: 0.5418\n",
            "Epoch 8/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7333 - loss: 0.5440 - val_accuracy: 0.7387 - val_loss: 0.5415\n",
            "Epoch 9/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7341 - loss: 0.5427 - val_accuracy: 0.7345 - val_loss: 0.5417\n",
            "Epoch 10/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7344 - loss: 0.5408 - val_accuracy: 0.7398 - val_loss: 0.5420\n",
            "Epoch 11/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7307 - loss: 0.5434 - val_accuracy: 0.7407 - val_loss: 0.5422\n",
            "Epoch 12/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7341 - loss: 0.5404 - val_accuracy: 0.7369 - val_loss: 0.5408\n",
            "Epoch 13/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7322 - loss: 0.5439 - val_accuracy: 0.7403 - val_loss: 0.5407\n",
            "Epoch 14/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7369 - loss: 0.5361 - val_accuracy: 0.7420 - val_loss: 0.5397\n",
            "Epoch 15/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7389 - loss: 0.5375 - val_accuracy: 0.7394 - val_loss: 0.5422\n",
            "Epoch 16/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7341 - loss: 0.5406 - val_accuracy: 0.7418 - val_loss: 0.5404\n",
            "Epoch 17/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7349 - loss: 0.5399 - val_accuracy: 0.7347 - val_loss: 0.5425\n",
            "Epoch 18/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7358 - loss: 0.5346 - val_accuracy: 0.7423 - val_loss: 0.5395\n",
            "Epoch 19/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7374 - loss: 0.5366 - val_accuracy: 0.7411 - val_loss: 0.5391\n",
            "Epoch 20/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7314 - loss: 0.5412 - val_accuracy: 0.7402 - val_loss: 0.5408\n",
            "Epoch 21/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7325 - loss: 0.5435 - val_accuracy: 0.7385 - val_loss: 0.5417\n",
            "Epoch 22/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7399 - loss: 0.5344 - val_accuracy: 0.7378 - val_loss: 0.5416\n",
            "Epoch 23/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7354 - loss: 0.5372 - val_accuracy: 0.7414 - val_loss: 0.5405\n",
            "Epoch 24/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7357 - loss: 0.5352 - val_accuracy: 0.7380 - val_loss: 0.5423\n",
            "Epoch 25/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7412 - loss: 0.5297 - val_accuracy: 0.7416 - val_loss: 0.5408\n",
            "Epoch 26/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7395 - loss: 0.5357 - val_accuracy: 0.7396 - val_loss: 0.5413\n",
            "Epoch 27/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7420 - loss: 0.5363 - val_accuracy: 0.7400 - val_loss: 0.5415\n",
            "Epoch 28/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7397 - loss: 0.5317 - val_accuracy: 0.7413 - val_loss: 0.5421\n",
            "Epoch 29/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7431 - loss: 0.5312 - val_accuracy: 0.7405 - val_loss: 0.5419\n",
            "Epoch 30/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7325 - loss: 0.5395 - val_accuracy: 0.7400 - val_loss: 0.5421\n",
            "Epoch 31/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7414 - loss: 0.5356 - val_accuracy: 0.7411 - val_loss: 0.5420\n",
            "Epoch 32/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7440 - loss: 0.5306 - val_accuracy: 0.7405 - val_loss: 0.5447\n",
            "Epoch 33/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7451 - loss: 0.5287 - val_accuracy: 0.7438 - val_loss: 0.5420\n",
            "Epoch 34/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7406 - loss: 0.5296 - val_accuracy: 0.7407 - val_loss: 0.5435\n",
            "Epoch 35/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7408 - loss: 0.5330 - val_accuracy: 0.7396 - val_loss: 0.5435\n",
            "Epoch 36/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7395 - loss: 0.5320 - val_accuracy: 0.7422 - val_loss: 0.5425\n",
            "Epoch 37/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7325 - loss: 0.5393 - val_accuracy: 0.7405 - val_loss: 0.5425\n",
            "Epoch 38/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7418 - loss: 0.5267 - val_accuracy: 0.7416 - val_loss: 0.5430\n",
            "Epoch 39/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7402 - loss: 0.5287 - val_accuracy: 0.7392 - val_loss: 0.5420\n",
            "Epoch 40/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7435 - loss: 0.5285 - val_accuracy: 0.7411 - val_loss: 0.5432\n",
            "Epoch 41/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7376 - loss: 0.5312 - val_accuracy: 0.7407 - val_loss: 0.5448\n",
            "Epoch 42/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7460 - loss: 0.5255 - val_accuracy: 0.7405 - val_loss: 0.5434\n",
            "Epoch 43/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7400 - loss: 0.5302 - val_accuracy: 0.7425 - val_loss: 0.5460\n",
            "Epoch 44/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7388 - loss: 0.5288 - val_accuracy: 0.7405 - val_loss: 0.5455\n",
            "Epoch 45/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7386 - loss: 0.5312 - val_accuracy: 0.7420 - val_loss: 0.5432\n",
            "Epoch 46/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7408 - loss: 0.5288 - val_accuracy: 0.7396 - val_loss: 0.5440\n",
            "Epoch 47/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7433 - loss: 0.5259 - val_accuracy: 0.7394 - val_loss: 0.5481\n",
            "Epoch 48/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7380 - loss: 0.5311 - val_accuracy: 0.7403 - val_loss: 0.5453\n",
            "Epoch 49/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7426 - loss: 0.5264 - val_accuracy: 0.7398 - val_loss: 0.5435\n",
            "Epoch 50/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7370 - loss: 0.5292 - val_accuracy: 0.7400 - val_loss: 0.5458\n",
            "Epoch 51/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7409 - loss: 0.5256 - val_accuracy: 0.7396 - val_loss: 0.5459\n",
            "Epoch 52/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7350 - loss: 0.5307 - val_accuracy: 0.7411 - val_loss: 0.5450\n",
            "Epoch 53/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7395 - loss: 0.5288 - val_accuracy: 0.7396 - val_loss: 0.5447\n",
            "Epoch 54/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7443 - loss: 0.5244 - val_accuracy: 0.7413 - val_loss: 0.5445\n",
            "Epoch 55/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7374 - loss: 0.5300 - val_accuracy: 0.7398 - val_loss: 0.5454\n",
            "Epoch 56/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7416 - loss: 0.5269 - val_accuracy: 0.7414 - val_loss: 0.5455\n",
            "Epoch 57/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7387 - loss: 0.5310 - val_accuracy: 0.7387 - val_loss: 0.5455\n",
            "Epoch 58/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7416 - loss: 0.5273 - val_accuracy: 0.7400 - val_loss: 0.5484\n",
            "Epoch 59/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7468 - loss: 0.5230 - val_accuracy: 0.7403 - val_loss: 0.5473\n",
            "Epoch 60/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7392 - loss: 0.5300 - val_accuracy: 0.7418 - val_loss: 0.5456\n",
            "Epoch 61/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7424 - loss: 0.5275 - val_accuracy: 0.7407 - val_loss: 0.5455\n",
            "Epoch 62/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7417 - loss: 0.5260 - val_accuracy: 0.7413 - val_loss: 0.5472\n",
            "Epoch 63/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7408 - loss: 0.5298 - val_accuracy: 0.7389 - val_loss: 0.5463\n",
            "Epoch 64/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7417 - loss: 0.5293 - val_accuracy: 0.7398 - val_loss: 0.5476\n",
            "Epoch 65/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7402 - loss: 0.5296 - val_accuracy: 0.7411 - val_loss: 0.5472\n",
            "Epoch 66/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7392 - loss: 0.5274 - val_accuracy: 0.7418 - val_loss: 0.5480\n",
            "Epoch 67/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7470 - loss: 0.5229 - val_accuracy: 0.7422 - val_loss: 0.5480\n",
            "Epoch 68/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7445 - loss: 0.5219 - val_accuracy: 0.7418 - val_loss: 0.5481\n",
            "Epoch 69/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7397 - loss: 0.5284 - val_accuracy: 0.7392 - val_loss: 0.5495\n",
            "Epoch 70/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7408 - loss: 0.5286 - val_accuracy: 0.7409 - val_loss: 0.5464\n",
            "Epoch 71/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7432 - loss: 0.5259 - val_accuracy: 0.7422 - val_loss: 0.5485\n",
            "Epoch 72/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7396 - loss: 0.5290 - val_accuracy: 0.7402 - val_loss: 0.5495\n",
            "Epoch 73/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7403 - loss: 0.5293 - val_accuracy: 0.7411 - val_loss: 0.5490\n",
            "Epoch 74/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7427 - loss: 0.5249 - val_accuracy: 0.7409 - val_loss: 0.5511\n",
            "Epoch 75/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7414 - loss: 0.5284 - val_accuracy: 0.7422 - val_loss: 0.5507\n",
            "Epoch 76/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7395 - loss: 0.5312 - val_accuracy: 0.7389 - val_loss: 0.5497\n",
            "Epoch 77/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7336 - loss: 0.5364 - val_accuracy: 0.7405 - val_loss: 0.5499\n",
            "Epoch 78/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7437 - loss: 0.5254 - val_accuracy: 0.7389 - val_loss: 0.5512\n",
            "Epoch 79/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7436 - loss: 0.5302 - val_accuracy: 0.7387 - val_loss: 0.5500\n",
            "Epoch 80/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7420 - loss: 0.5239 - val_accuracy: 0.7394 - val_loss: 0.5493\n",
            "Epoch 81/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7364 - loss: 0.5303 - val_accuracy: 0.7402 - val_loss: 0.5492\n",
            "Epoch 82/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7422 - loss: 0.5275 - val_accuracy: 0.7422 - val_loss: 0.5495\n",
            "Epoch 83/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7429 - loss: 0.5279 - val_accuracy: 0.7427 - val_loss: 0.5488\n",
            "Epoch 84/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7396 - loss: 0.5299 - val_accuracy: 0.7405 - val_loss: 0.5486\n",
            "Epoch 85/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7425 - loss: 0.5265 - val_accuracy: 0.7387 - val_loss: 0.5504\n",
            "Epoch 86/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7443 - loss: 0.5224 - val_accuracy: 0.7422 - val_loss: 0.5477\n",
            "Epoch 87/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7406 - loss: 0.5308 - val_accuracy: 0.7440 - val_loss: 0.5485\n",
            "Epoch 88/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7443 - loss: 0.5248 - val_accuracy: 0.7422 - val_loss: 0.5484\n",
            "Epoch 89/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7425 - loss: 0.5268 - val_accuracy: 0.7391 - val_loss: 0.5488\n",
            "Epoch 90/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7400 - loss: 0.5269 - val_accuracy: 0.7414 - val_loss: 0.5486\n",
            "Epoch 91/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7432 - loss: 0.5256 - val_accuracy: 0.7398 - val_loss: 0.5494\n",
            "Epoch 92/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7437 - loss: 0.5244 - val_accuracy: 0.7411 - val_loss: 0.5478\n",
            "Epoch 93/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7428 - loss: 0.5275 - val_accuracy: 0.7405 - val_loss: 0.5502\n",
            "Epoch 94/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7410 - loss: 0.5257 - val_accuracy: 0.7391 - val_loss: 0.5487\n",
            "Epoch 95/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7462 - loss: 0.5200 - val_accuracy: 0.7402 - val_loss: 0.5484\n",
            "Epoch 96/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7410 - loss: 0.5265 - val_accuracy: 0.7403 - val_loss: 0.5501\n",
            "Epoch 97/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7475 - loss: 0.5226 - val_accuracy: 0.7378 - val_loss: 0.5505\n",
            "Epoch 98/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7433 - loss: 0.5284 - val_accuracy: 0.7400 - val_loss: 0.5492\n",
            "Epoch 99/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7442 - loss: 0.5251 - val_accuracy: 0.7396 - val_loss: 0.5475\n",
            "Epoch 100/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7434 - loss: 0.5263 - val_accuracy: 0.7418 - val_loss: 0.5516\n",
            "Epoch 101/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7445 - loss: 0.5214 - val_accuracy: 0.7382 - val_loss: 0.5480\n",
            "Epoch 102/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7375 - loss: 0.5287 - val_accuracy: 0.7414 - val_loss: 0.5479\n",
            "Epoch 103/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7450 - loss: 0.5247 - val_accuracy: 0.7363 - val_loss: 0.5512\n",
            "Epoch 104/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7389 - loss: 0.5297 - val_accuracy: 0.7425 - val_loss: 0.5482\n",
            "Epoch 105/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7413 - loss: 0.5302 - val_accuracy: 0.7431 - val_loss: 0.5494\n",
            "Epoch 106/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7398 - loss: 0.5311 - val_accuracy: 0.7425 - val_loss: 0.5473\n",
            "Epoch 107/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7458 - loss: 0.5236 - val_accuracy: 0.7409 - val_loss: 0.5485\n",
            "Epoch 108/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7398 - loss: 0.5268 - val_accuracy: 0.7405 - val_loss: 0.5482\n",
            "Epoch 109/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7430 - loss: 0.5267 - val_accuracy: 0.7425 - val_loss: 0.5486\n",
            "Epoch 110/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7420 - loss: 0.5221 - val_accuracy: 0.7420 - val_loss: 0.5491\n",
            "Epoch 111/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7435 - loss: 0.5255 - val_accuracy: 0.7416 - val_loss: 0.5490\n",
            "Epoch 112/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7388 - loss: 0.5286 - val_accuracy: 0.7414 - val_loss: 0.5503\n",
            "Epoch 113/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7432 - loss: 0.5250 - val_accuracy: 0.7367 - val_loss: 0.5508\n",
            "Epoch 114/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7423 - loss: 0.5253 - val_accuracy: 0.7444 - val_loss: 0.5516\n",
            "Epoch 115/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7433 - loss: 0.5287 - val_accuracy: 0.7385 - val_loss: 0.5535\n",
            "Epoch 116/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7426 - loss: 0.5243 - val_accuracy: 0.7411 - val_loss: 0.5528\n",
            "Epoch 117/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7404 - loss: 0.5267 - val_accuracy: 0.7427 - val_loss: 0.5524\n",
            "Epoch 118/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7381 - loss: 0.5309 - val_accuracy: 0.7403 - val_loss: 0.5509\n",
            "Epoch 119/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7426 - loss: 0.5259 - val_accuracy: 0.7416 - val_loss: 0.5518\n",
            "Epoch 120/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7442 - loss: 0.5250 - val_accuracy: 0.7416 - val_loss: 0.5515\n",
            "Epoch 121/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7437 - loss: 0.5262 - val_accuracy: 0.7405 - val_loss: 0.5496\n",
            "Epoch 122/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7407 - loss: 0.5274 - val_accuracy: 0.7374 - val_loss: 0.5499\n",
            "Epoch 123/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7385 - loss: 0.5298 - val_accuracy: 0.7413 - val_loss: 0.5492\n",
            "Epoch 124/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7454 - loss: 0.5208 - val_accuracy: 0.7382 - val_loss: 0.5509\n",
            "Epoch 125/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7413 - loss: 0.5259 - val_accuracy: 0.7394 - val_loss: 0.5498\n",
            "Epoch 126/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7417 - loss: 0.5232 - val_accuracy: 0.7400 - val_loss: 0.5488\n",
            "Epoch 127/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7487 - loss: 0.5205 - val_accuracy: 0.7409 - val_loss: 0.5505\n",
            "Epoch 128/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7393 - loss: 0.5305 - val_accuracy: 0.7413 - val_loss: 0.5507\n",
            "Epoch 129/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7410 - loss: 0.5253 - val_accuracy: 0.7427 - val_loss: 0.5519\n",
            "Epoch 130/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7467 - loss: 0.5217 - val_accuracy: 0.7414 - val_loss: 0.5531\n",
            "Epoch 131/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7410 - loss: 0.5274 - val_accuracy: 0.7407 - val_loss: 0.5512\n",
            "Epoch 132/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7419 - loss: 0.5280 - val_accuracy: 0.7409 - val_loss: 0.5517\n",
            "Epoch 133/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7436 - loss: 0.5227 - val_accuracy: 0.7400 - val_loss: 0.5524\n",
            "Epoch 134/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7436 - loss: 0.5255 - val_accuracy: 0.7398 - val_loss: 0.5517\n",
            "Epoch 135/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7448 - loss: 0.5219 - val_accuracy: 0.7374 - val_loss: 0.5545\n",
            "Epoch 136/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7392 - loss: 0.5284 - val_accuracy: 0.7391 - val_loss: 0.5515\n",
            "Epoch 137/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7429 - loss: 0.5253 - val_accuracy: 0.7400 - val_loss: 0.5521\n",
            "Epoch 138/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7411 - loss: 0.5240 - val_accuracy: 0.7416 - val_loss: 0.5510\n",
            "Epoch 139/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7389 - loss: 0.5274 - val_accuracy: 0.7413 - val_loss: 0.5505\n",
            "Epoch 140/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7415 - loss: 0.5284 - val_accuracy: 0.7416 - val_loss: 0.5513\n",
            "Epoch 141/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7423 - loss: 0.5292 - val_accuracy: 0.7389 - val_loss: 0.5519\n",
            "Epoch 142/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7419 - loss: 0.5267 - val_accuracy: 0.7409 - val_loss: 0.5517\n",
            "Epoch 143/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7437 - loss: 0.5235 - val_accuracy: 0.7387 - val_loss: 0.5513\n",
            "Epoch 144/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7449 - loss: 0.5223 - val_accuracy: 0.7423 - val_loss: 0.5512\n",
            "Epoch 145/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7423 - loss: 0.5242 - val_accuracy: 0.7420 - val_loss: 0.5521\n",
            "Epoch 146/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7423 - loss: 0.5275 - val_accuracy: 0.7394 - val_loss: 0.5525\n",
            "Epoch 147/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7377 - loss: 0.5301 - val_accuracy: 0.7409 - val_loss: 0.5519\n",
            "Epoch 148/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7423 - loss: 0.5231 - val_accuracy: 0.7385 - val_loss: 0.5544\n",
            "Epoch 149/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7432 - loss: 0.5258 - val_accuracy: 0.7380 - val_loss: 0.5537\n",
            "Epoch 150/150\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7367 - loss: 0.5290 - val_accuracy: 0.7369 - val_loss: 0.5509\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the final model\n",
        "nn.save(\"AlphabetSoupCharity_Optimization.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IIgle0T6ai8",
        "outputId": "ffda505e-f382-469a-adb8-fc80aec16ef8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on the test set\n",
        "loss, accuracy = nn.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6pb-jX76jy2",
        "outputId": "5884498b-6d51-46c3-ad69-207477f51aaf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7250 - loss: 0.5635\n",
            "Test Accuracy: 0.73\n"
          ]
        }
      ]
    }
  ]
}